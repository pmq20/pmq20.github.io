% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

\documentclass{beamer}
\usepackage{tikz}
\usepackage[USenglish]{babel}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{algpseudocode}
\usepackage{ulem}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\sign}{sign}
\usefonttheme[onlymath]{serif}
\mode<presentation>
{
  \usetheme{Warsaw}
}
\newcommand*{\Z}{\makebox[1.5ex]{\textbf{$\cdot$}}}

\title{Zang and Wang 2019: Neural Dynamics on Complex Networks}

\author{Minqi Pan}

\date{\today}

\AtBeginSubsection[]
{
  \begin{frame}<beamer>{Outline}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Neural Dynamics on Complex Networks}
\begin{itemize}
\item AAAI 2020, Best Paper of ``The 1st International Workshop on Deep Learning on Graphs: Methodologies and Applications'', Feb 8th, 2020
\item Chengxi Zang and Fei Wang
\item Weill Cornell Medicine
\end{itemize}
\end{frame}

\begin{frame}{Outline}
  \tableofcontents
\end{frame}

\section{General Framework}
\subsection{Neural Dynamics on Complex Networks (NDCN)}
\begin{frame}{The Differential Equation System}
\[
\frac{dX(t)}{dt}=f(X(t),G,W(t),t)
\]
\begin{itemize}
\item $X(t)\in\mathbb{R}^{n\times d}$: the state (node feature values) of a dynamic system consisting of $n$ linked nodes at time $t\in[0,\infty)$, and each node is characterized by $d$ dimensional features
\item $f:\mathbb{R}^{n\times d}\to\mathbb{R}^{n\times d}$: a function governing the dynamics of the system, which could be either linear or nonlinear
\item $G=(\mathcal{V},\mathcal{E})$: the network structure capturing how the nodes are linked to each other
\item $W(t)$: the parameters which control how the system evolves over time
\item $X(0)=X_0$: the initial state of this system at time $t=0$
\end{itemize}
\end{frame}

\begin{frame}{Semantic Labels}
\begin{itemize}
\item $Y(X,\Theta,t)\in\{0,1\}^{n\times k}$: the semantic labels of the nodes at time $t$
\item $\Theta$: the parameters of this classification function
\end{itemize}
\end{frame}

\begin{frame}{Problem \#1: Network Dynamics Learning}
\begin{itemize}
\item Given a graph $G$ and the observations of the states of system:\[
\{\hat{X(t_1)},\hat{X(t_2)},\dots,\hat{X(t_T)}:0\leqslant t_1\leqslant\dots\leqslant t_T\}
\]
\item $t_1$ to $t_T$ are arbitrary physical time stamps, possibly irregularly sampled with different observational time intervals
\item How to learn the continous-time dynamics $\frac{dX(t)}{dt}$ on complex networks from empirical data? Can we learn differential equation systems $\frac{dX(t)}{dt}=f(X(t),G,W(t),t)$ to generate or predict continuous-time dynamics $X(t)$ at arbitrary physical time $t$?
\begin{itemize}
\item ``extrapolation prediction'': when $t>t_T$
\item ``interpolation prediction'': when $t<t_T$ and $t\ne\{t_1,\dots,t_T\}$ 
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Problem \#2: Structured Sequence Learning}
\begin{itemize}
\item A special case of the problem of Network Dynamics Learning
\item $t_1,t_2,\dots,t_T$ are sampled regularly with equal time intervals
\item Emphasizing on sequential order instead of arbitrary physical time
\item The goal is to exptrapolate next $m$ steps:\[
X[t_T+1],\dots,X[t_T+m]
\]
\end{itemize}
\end{frame}

\begin{frame}{Problem \#3: One-snapshot Learning}
\begin{itemize}
\item A special case of the problem of Network Dynamics Learning
\item How to learn the semantic labels of $Y(X(t_T))$ at the moment $t=t_T$ for each node?
\item Emphasizing on a specific moment
\item Without loss of generality, we focus on the moment at the terminal time $t_T$
\item The function $Y$ can be a mapping from the nodes' states (e.g. humidity) to their labels (e.g. taking umbrella or not)
\end{itemize}
\end{frame}

\begin{frame}{Network Dynamics \#1: Heat Diffusion}
\begin{itemize}
\item Let $\overrightarrow{x_i(t)}\in\mathbb{R}^{d\times1}$ be $d$ dimensional features of node $i$ at time $t$
\item Thus\[
X(t)=\begin{bmatrix}\vdots\\\overrightarrow{x_i(t)}\\\vdots\end{bmatrix}
\]
\item The heat diffusion dynamics governed by Newton's law of cooling\[
\frac{d\overrightarrow{x_i(t)}}{dt}=-k_{i,j}\sum_{j=1}^nA_{i,j}(\overrightarrow{x_i}-\overrightarrow{x_j})
\]which states that the rate of heat change of node $i$ is proportional to the difference of the temperature between node $i$ and its neighbors with heat capacity matrix $A$
\end{itemize}
\end{frame}

\begin{frame}{Network Dynamics \#2: Mutualistic Interaction}
\begin{itemize}
\item The mutualistic differential equation systems capture the abundance $\overrightarrow{x_i(t)}$ of species $i$ in ecology:\[
\frac{d\overrightarrow{x_i(t)}}{dt}=b_i+\overrightarrow{x_i}\left(1-\frac{\overrightarrow{x_i}}{k_i}\right)\left(\frac{\overrightarrow{x_i}}{c_i}-1\right)+\sum_{j=1}^nA_{i,j}\frac{\overrightarrow{x_i}\overrightarrow{x_j}}{d_i+e_i\overrightarrow{x_i}+h_j\overrightarrow{x_j}}
\]
\begin{itemize}
\item with incoming migration term $b_i$
\item with logistic growth with population capacity $k_i$
\item with Allee effect with cold-start threshold $c_i$
\item with mutualistic interaction term with interaction network $A$
\end{itemize}
\item For brevity, the operations between vectors are element-wise
\end{itemize}
\end{frame}

\begin{frame}{Network Dynamics \#3: Gene Regulatory}
\begin{itemize}
\item Governed by Michaelis-Menten equation\[
\frac{d\overrightarrow{x_i(t)}}{dt}=-b_i\overrightarrow{x_i(t)}^f+\sum_{j=1}^nA_{i,j}\frac{\overrightarrow{x_j}^h}{\overrightarrow{x_j}^h+1}
\]
\begin{itemize}
\item the 1st term models degradation when $f=1$ or dimerization when $f=2$
\item the 2nd term captures genetic activation tuned by the Hill coefficient $h$
\end{itemize}
\end{itemize}
\end{frame}


\begin{frame}{Complex Networks}
\begin{enumerate}
\item ``Grid'' where each node is connected with 8 neighbors
\item ``Random'' generated by Erd\'os and R\'enyi model
\item ``Power-law'' generated by Albert-Barab\'asi model
\item ``Small-world'' generated by Watts-Strogatz model
\item ``Community'' generated by random partitionmodel
\end{enumerate}
\end{frame}

\begin{frame}{Visualization}
\begin{itemize}
\item To visualize dynamics on complex networks over time is not trivial
\item We firsts generate a network with $n$ nodes by aforementioned network models
\item The nodes are re-ordered according to the community detection method by Newman
\item Each node has a unique label from $1$ to $n$
\item We layout these nodes on a $2$-dimensional $\sqrt{n}\times\sqrt{n}$ grid and each grid point $(r,c)\in\mathbb{N}^2$ represents the $i^\text{th}$ node where $i=r\sqrt{n}+c+1$
\item Thus, nodes' states $X(t)\in\mathbb{R}^{n\times d}$ at time $t$ when $d=1$ can be visualized as a scalar field function $X:\mathbb{N}^2\to\mathbb{R}$ over the grid
\end{itemize}
\end{frame}

\begin{frame}{General Framework}
\[
\begin{split}
\argmin_{W(t),\Theta(T)}\text{ }&\mathcal{L}=\int_0^T\mathcal{R}\left(X(t),G,W,t\right)dt+\mathcal{S}\left(Y(X(T),\Theta)\right)\\
\text{subject to }&\frac{dX(t)}{dt}=f(X(t),G,W,t),X(0)
\end{split}
\]
\begin{itemize}
\item $\mathcal{R}(X(t),G,W,t)$: the running loss of the dynamics on graph at time $t$
\item $\mathcal{S}(Y(X(T),\Theta))$: the terminal semantic loss at time $T$
\item By integrating $\frac{dX(t)}{dt}=f(X(t),G,W,t)$ over time $t$ from initial state $X_0$, a.k.a. solving the initial value problem for this differential equation system, we can get the continous-time dynamics $X(t)=x(0)+\int_0^Tf(X(\tau),G,W,\tau)d\tau$ at arbitrary time moment $t>0$
\end{itemize}
\end{frame}

\begin{frame}{As an Optimal Control Problem}
\begin{itemize}
\item By solving the above optimization problem
\begin{itemize}
\item Obtain the best control parameters $W(t)$ for differential equation system $\frac{dX}{dt}=f(X,G,W,t)$
\item Obtain the best classification parameters $\Theta$ for semantic function $Y(X(t),\Theta)$
\end{itemize}
\item Differences from the traditional Optimal Control framework: We model the differential equation systems\[
\frac{dX}{dt}=f(X,G,W,t)
\]by graph neural networks
\end{itemize}
\end{frame}

\begin{frame}{In a Dynamical System View}
\begin{itemize}
\item By integration $\frac{dX}{dt}=f(X,G,W,t)$ over continuous time, namely\[
X(t)=X(0)+\int_0^tf(X(\tau),G,W,\tau)d\tau
\]we get our differential deep learning models
\item Our differential deep learning models can be a time-varying coefficient dynamical system where $W(t)$ changes over time
\item Or a constant coefficient dynamical system when $W$ is constant over time for parameter sharing
\end{itemize}
\end{frame}

\begin{frame}{Further Encoding (1)}
\[
\begin{split}
\argmin_{W(t),\Theta(T)}\text{ }&\mathcal{L}=\int_0^T\mathcal{R}\left(X(t),G,W,t\right)dt+\mathcal{S}\left(Y(X(T),\Theta)\right)\\
\text{subject to }&X_h(t)=f_\text{encode}(X(t))\\
&\frac{dX_h(t)}{dt}=f(X_h(t),G,W,t),X_h(0)\\
&X(t)=f_\text{decode}(X_h(t))
\end{split}
\]
\begin{itemize}
\item To further increase the express ability of our model, we can encode the network signal $X(t)$ from the original space to $X_h(t)$ in hidden space (usually with a different number of dimensions), and learn the dynamics in such a space
\end{itemize}
\end{frame}

\begin{frame}{Further Encoding (2)}
\[
\begin{split}
\argmin_{W(t),\Theta(T)}\text{ }&\mathcal{L}=\int_0^T\mathcal{R}\left(X(t),G,W,t\right)dt+\mathcal{S}\left(Y(X(T),\Theta)\right)\\
\text{subject to }&X_h(t)=f_\text{encode}(X(t))\\
&\frac{dX_h(t)}{dt}=f(X_h(t),G,W,t),X_h(0)\\
&X(t)=f_\text{decode}(X_h(t))
\end{split}
\]
\begin{itemize}
\item The 1st constraint transforms $X(t)$ into hidden space $X_h(t)$
\item The 2nd constraint is the governing dynamics in the hidden space
\item The 3rd constraint decodes the hidden signal back to the original space
\end{itemize}
\end{frame}

\begin{frame}{Further Encoding (3)}
\[
\begin{split}
\argmin_{W(t),\Theta(T)}\text{ }&\mathcal{L}=\int_0^T\mathcal{R}\left(X(t),G,W,t\right)dt+\mathcal{S}\left(Y(X(T),\Theta)\right)\\
\text{subject to }&X_h(t)=f_\text{encode}(X(t))\\
&\frac{dX_h(t)}{dt}=f(X_h(t),G,W,t),X_h(0)\\
&X(t)=f_\text{decode}(X_h(t))
\end{split}
\]
\begin{itemize}
\item The design of $f_\text{encode}, f, f_\text{decode}$ are flexible to be any neural structure, e.g. Softmax as the decoder for classficiation
\item We denote this model as ``NDCN''
\end{itemize}
\end{frame}

\begin{frame}{Discrete Layers vs. Continuous Layers}
\begin{itemize}
\item The deep learning methods with $L$ hidden neural layers $f_*$ are\[
X[L]=f_L\circ\dots\circ f_2\circ f_1(X[0]),
\]which are iterated maps with an integer number of discrete layers and thus cannot learn continous-time dynamics $X(t)$ at arbitrary time
\item In contrast, our model\[
X(t)=X(0)+\int_0^t f(X(\tau),G,W,\tau)d\tau
\]can have contiunous layers with a real number $t$ depth corresponding to continous-time dynamics
\end{itemize}
\end{frame}

\begin{frame}{Solving the Initial Value Problem}
\begin{itemize}
\item Integrate the differential equation systems over time by numerical methods
\item The numerical methods can approximate continuous-time dynamics\[
X(t)=X(0)+\int_0^tf(X(\tau),G,W,\tau)d\tau
\]at arbitrary time $t$ accurately with guaranteed error
\item In order to learn the learnable parameters $W$, we back-propogate the gradients of the loss function w.r.t. the control parameters $\frac{\partial\mathcal{L}}{\partial W}$ over the numerical integration process backwards in an end-to-end manner, and solve the optimization problem by stochastic gradient descent methods
\end{itemize}
\end{frame}

\section{Learning Continuous-Time Network Dynamics}
\subsection{Model Instance}

\begin{frame}{The Continous-time Setting}
\begin{itemize}
\item The observational times $t_1$ to $t_T$ of the observed states of system\[
\{\hat{X(t_1)},\hat{X(t_2)},\dots,\hat{X(t_T)}:0\leqslant t_1\leqslant\dots\leqslant t_T\}
\]are arbitrary physical time stamps which are irregularly sampled with different observational time intervals
\item Extrapolation prediction is to predict\[
X(t)
\]at arbitrary physical time moment $t$ when $t>t_T$
\item Interpolation prediction is to predict\[
X(t)
\] when $t<t_T$ and $t\ne\{t_1,\dots,t_T\}$
\end{itemize}
\end{frame}

\begin{frame}{Model Instance (1)}\[
\begin{split}
\argmin_{W_*,b_*}\text{ }&\mathcal{L}=\int_0^T|X(t)-\hat{X(t)}|dt\\
\text{subject to }&X_h(t)=\tanh(X(t)W_e+b_e)W_0+b_0\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t)W+b),X_h(0)\\
&X(t)=X_h(t)W_d+b_d
\end{split}
\]
\begin{itemize}
\item Loss: emphasizing on running loss only; use $\ell_1$-norm loss as the running loss $\mathcal R$
\item $|\cdot|$: $\ell_1$-norm loss (element-wise absolute value difference) between $X(t)$ and $\hat{X(t)}$ at time $t\in[0,T]$
\end{itemize}
\end{frame}

\begin{frame}{Model Instance (2)}\[
\begin{split}
\argmin_{W_*,b_*}\text{ }&\mathcal{L}=\int_0^T|X(t)-\hat{X(t)}|dt\\
\text{subject to }&X_h(t)=\tanh(X(t)W_e+b_e)W_0+b_0\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t)W+b),X_h(0)\\
&X(t)=X_h(t)W_d+b_d
\end{split}
\]
\begin{itemize}
\item The encoding function: two fully connected neural layers with a nonlinear hidden layer as the encoding function
\item the linear decoding function: for regression tasks in the original signal space
\end{itemize}
\end{frame}

\begin{frame}{Model Instance (3)}\[
\begin{split}
\argmin_{W_*,b_*}\text{ }&\mathcal{L}=\int_0^T|X(t)-\hat{X(t)}|dt\\
\text{subject to }&X_h(t)=\tanh(X(t)W_e+b_e)W_0+b_0\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t)W+b),X_h(0)\\
&X(t)=X_h(t)W_d+b_d
\end{split}
\]
\begin{itemize}
\item $\hat{X(t)}\in\mathbb{R}^{n\times d}$: the supervised dynamic information available at time stamp $t$
\begin{itemize}
\item in the semi-supervised case the missing information can be padded by $0$
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Model Instance (4)}\[
\begin{split}
\argmin_{W_*,b_*}\text{ }&\mathcal{L}=\int_0^T|X(t)-\hat{X(t)}|dt\\
\text{subject to }&X_h(t)=\tanh(X(t)W_e+b_e)W_0+b_0\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t)W+b),X_h(0)\\
&X(t)=X_h(t)W_d+b_d
\end{split}
\]
\begin{itemize}
\item $\Phi=D^{-\frac{1}{2}}(D-A)D^{-\frac{1}{2}}\in\mathbb{R}^{n\times n}$: graph diffusion operator to model the instantaneous network dynamics in the hidden space, which is the normalized graph Laplacian
\begin{itemize}
\item $A\in\mathbb{R}^{n\times n}$: the adjacency matrix of the network
\item $D\in\mathbb{R}^{n\times n}$: the corresponding node degree matrix
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Model Instance (5)}\[
\begin{split}
\argmin_{W_*,b_*}\text{ }&\mathcal{L}=\int_0^T|X(t)-\hat{X(t)}|dt\\
\text{subject to }&X_h(t)=\tanh(X(t)W_e+b_e)W_0+b_0\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t)W+b),X_h(0)\\
&X(t)=X_h(t)W_d+b_d
\end{split}
\]
\begin{itemize}
\item $W\in\mathbb{R}^{d_e\times d_e}$ and $b\in\mathbb{R}^{n\times d_e}$: shared parameters (namely, the weights and bias of a linear connection layer) over time $t\in[0,T]$
\item $W_e\in\mathbb{R}^{d\times d_e}$ and $W_0\in\mathbb{R}^{d_2\times d}$: for decoding
\item $b_e,b_0,b,b_d$: the biases at the corresponding layer
\end{itemize}
\end{frame}

\begin{frame}{Model Instance (6)}\[
\begin{split}
\argmin_{W_*,b_*}\text{ }&\mathcal{L}=\int_0^T|X(t)-\hat{X(t)}|dt\\
\text{subject to }&X_h(t)=\tanh(X(t)W_e+b_e)W_0+b_0\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t)W+b),X_h(0)\\
&X(t)=X_h(t)W_d+b_d
\end{split}
\]
\begin{itemize}
\item We learn the parameters\[
W_e,W_0,W,W_d,b_e,b_0,b,b_d
\]from empirical data so that we can learn $X$ in a data-driven manner
\end{itemize}
\end{frame}


\begin{frame}{Model Instance (7)}\[
\begin{split}
\argmin_{W_*,b_*}\text{ }&\mathcal{L}=\int_0^T|X(t)-\hat{X(t)}|dt\\
\text{subject to }&X_h(t)=\tanh(X(t)W_e+b_e)W_0+b_0\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t)W+b),X_h(0)\\
&X(t)=X_h(t)W_d+b_d
\end{split}
\]
\begin{itemize}
\item $\frac{dX(t)}{dt}$: a single neural layer at time moment $t$
\item $X(t)$ at arbitrary time $t$ is achieved by integrating $\frac{dX(t)}{dt}$ over time, leading to a continous-time deep neural network:\[
X(t)=X(0)+\int_0^t\text{ReLU}(\Phi X(\tau)W+b)d\tau
\]
\end{itemize}
\end{frame}

\subsection{Experiments}
\begin{frame}{Baselines}
\begin{itemize}
\item There are no baselines for learning continous-time dynamics on complex networks
\item Thus we compare the ablation models of NDCN
\item By investigating ablation models we show that NDCN is a minimum model for this task
\end{itemize}
\end{frame}

\begin{frame}{Baseline \#1}
\begin{itemize}
\item Keep the loss function the same
\item The model without encoding and decoding functions
\item Thus no hidden space:\[
\frac{dX(t)}{dt}=\text{ReLU}(\Phi X(t)W+b),
\]
\item Namely ODE-GNN, which learns the dynamics in the original signal space $X(t)$
\end{itemize}
\end{frame}

\begin{frame}{Baseline \#2}
\begin{itemize}
\item Keep the loss function the same
\item The model without graph diffusion operator\[
\Phi: \frac{dX_h(t)}{dt}=\text{ReLU}(X_h(t)W+b),
\]
\item I.e. an ODE Neural Network, which can be though as a continous-time version of forward residual neural network
\end{itemize}
\end{frame}

\begin{frame}{Baseline \#3}
\begin{itemize}
\item Keep the loss function the same
\item The model without control parameters $W$:\[
\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t))
\]
\item No linear connnection layer between $t$ and $t+dt$ where $dt\to 0$
\item Thus indicating a determined dynamics to spread signals
\end{itemize}
\end{frame}

\begin{frame}{Experimental Setup (1)}
\begin{itemize}
\item We generate underlying networks with $400$ nodes by Network Dynamics \#1-\#3 and Complex Networks \#1-\#5
\item We set the initial value $X(0)$ the same for all the experiments
\item Thus different dynamics are only due to their different dynamic rules and underlying networks
\end{itemize}
\end{frame}

\begin{frame}{Experimental Setup (2)}
\begin{itemize}
\item We irregularly sample $120$ snapshots of the continuous-time dynamics\[
\{\hat{X(t_1)},\dots,\hat{X(t_{120})}:0\leqslant t_1<\dots<t_{120}\leqslant T\}
\]where the time intervals between $t_1,\dots,t_{120}$ are different
\item Training: Randomly choose $80$ snapshots from $\hat{X(t_1)}$ to $\hat{X(t_{100})}$
\item Interpolation testing: the left $20$ snapshots from $\hat{X(t_1)}$ to $\hat{X(t_{100})}$
\item Extrapolation testing: use the $20$ snapshots from $\hat{X(t_{101})}$ to $\hat{X(t_{120})}$
\end{itemize}
\end{frame}

\begin{frame}{Experimental Setup (3)}
\begin{itemize}
\item We use Dormand-Prince method to get the ground truth dynamics
\item We use Euler method in the forward process of our NDCN
\item We evaluate the results by $\ell_1$ loss and normalized $\ell_1$ loss (normalized by the mean element-wise value of $\hat{X(t)}$) and they lead to the same conclusion
\item Results are the mean and standard deviation of the loss over $20$ independent runs for $3$ dynamic laws on $5$ different networks by each method
\end{itemize}
\end{frame}

\begin{frame}{Results (Visual)}
\begin{itemize}
\item We find that one dyanmic law may behave quite different on different networks
\begin{itemize}
\item Heat dynamics may gradually die out to be stable but follow different dynamic pattern on different networks
\item Gene dynamics are asymptotically stable on grid but unstable on random networks or community networks
\item Both gene regulation dynamics and biological mutualistic dynamics show very bursty patterns on power-law networks
\end{itemize}
\item NDCN learns all these different network dynamics veryt well
\end{itemize}
\end{frame}

\begin{frame}{Results (Quantitative)}
\begin{itemize}
\item Each quantitative result is the normalized $\ell_1$ error with standard deviation (in percentage \%) from $20$ runs for $3$ dynamics on $5$ networks by each method
\item NDCN captures different dynamics on various complex networks accurately
\item NDCN outperforms all the continuous-time baselines by a large margin
\item NDCN potentially serves as a minimum model in learning contiunous-time dynamics on complex networks
\end{itemize}
\end{frame}

\section{Learning Regularly-Sampled Dynamics}
\subsection{Baselines, Experimental Setup and Results}
\begin{frame}{Baselines}
\begin{itemize}
\item We compare our model with the temporal-GNN models
\begin{itemize}
\item Temporal-GNN are usually combinations of RNN models and GNN models
\item Temporal-GNN models are usually used for next few step prediction and cannot be used for interpolation task (say, to predict $X[t_{1.23}]$)
\end{itemize}
\item We use GCN as a graph structure extractor
\item We use LSTM/GRU/RNN to learn the temporal relationship between ordered structured sequences
\end{itemize}
\end{frame}

\begin{frame}{Baseline \#1}
\begin{itemize}
\item We keep the loss function the same
\item LSTM-GNN: the temporal-GNN with LSTM cell\[
X[t+1]=\text{LSTM}(\text{GCN}(X[t],G))
\]
\end{itemize}
\end{frame}

\begin{frame}{Baseline \#2}
\begin{itemize}
\item We keep the loss function the same
\item GRU-GNN: the temporal-GNN with GRU cell\[
X[t+1]=\text{GRU}(\text{GCN}(X[t],G))
\]
\end{itemize}
\end{frame}

\begin{frame}{Baseline \#1}
\begin{itemize}
\item We keep the loss function the same
\item RNN-GNN: the temporal-GNN with RNN cell\[
X[t+1]=\text{RNN}(\text{GCN}(X[t],G))
\]
\end{itemize}
\end{frame}

\begin{frame}{Experimental Setup}
\begin{itemize}
\item We regularly sample $100$ snapshots of the continuous-time network dynamics\[
\{\hat{X[t_1]},\dots,\hat{X[t_{100}]}:0\leqslant t_1<\dots<t_{120}\leqslant T\}
\]where the time intervals between $t_1,\dots,t_{100}$ are the same
\item Training: use first $80$ snapshots $\hat{X[t_1]},\dots,\hat{X[t_{80}]}$
\item Prediction/Extrapolation Testing: use the left $20$ snapshots $\hat{X[t_{81}]},\dots,\hat{X[t_{100}]}$
\item We use $5$ and $10$ for hidden dimension of GCN and RNN models respectively
\end{itemize}
\end{frame}

\begin{frame}{Results}
\begin{itemize}
\item GRU-GNN model works well in mutualistic dynamics on random network and community network
\item NDCN predicts different dynamics on these complex networks accurately
\item NDCN outperforms the baselines in almost all the settings
\item NDCN captures the structure and dynamics in a much more succinct way
\item NDCN only has $901$ parameters to learn, compared to $24k,64k,84k$ of RNN-GCN, GRU-GNN, LSTM-GNN, respectively
\end{itemize}
\end{frame}

\section{Learning Semantic Labels at Terminal Time}
\subsection{Model Instance}
\begin{frame}{Learning the Semantic Labels at the Terminal Time}
\begin{itemize}
\item Existing GNNs (s.o.t.a. in graph semi-supervised classification task) usually adopt $1$ or $2$ hidden layers
\item NDCN follows the perspective of a dynamical system and goes beyond an integer number $L$ of hidden layers in GNNS to a real number depth $t$ of hidden layers, implying continuous-time dynamics on the graph
\item By integration continous-time dynamics on the graph over time, we get a more fine-grained forward process
\item Thus NDCN model shows very competitive even better results compared with s.o.t.a. GNN models which may have sophisticated parameters (e.g. attention)
\end{itemize}
\end{frame}

\begin{frame}{Model Instance (1)}\[
\begin{split}
\argmin_{W_e,b_e,W_d,b_d}\text{ }&\mathcal{L}=\int_0^T\mathcal{R}(t)dt-\sum_{i=1}^n\sum_{k=1}^c\hat{Y}_{i,k}(T)\log Y_{i,k}(T)\\
\text{subject to }&X_h(0)=\tanh(X(0)W_e+b_e)\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t))\\
&X(T)=\text{Softmax}(X_h(T)W_d+b_d)
\end{split}
\]
\begin{itemize}
\item Loss: terminal semantic loss $\mathcal{S}(Y(T))$ modeled by the cross-entropy loss for classification task
\end{itemize}
\end{frame}

\begin{frame}{Model Instance (2)}\[
\begin{split}
\argmin_{W_e,b_e,W_d,b_d}\text{ }&\mathcal{L}=\int_0^T\mathcal{R}(t)dt-\sum_{i=1}^n\sum_{k=1}^c\hat{Y}_{i,k}(T)\log Y_{i,k}(T)\\
\text{subject to }&X_h(0)=\tanh(X(0)W_e+b_e)\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t))\\
&X(T)=\text{Softmax}(X_h(T)W_d+b_d)
\end{split}
\]
\begin{itemize}
\item $Y(T)\in\mathbb{R}^{n\times c}$: the label distributions of nodes at time $T\in\mathbb{R}$ whose 
\begin{itemize}
\item $Y_{i,k}(T)$: the probability of the node $i=1,\dots,n$ with label $k=1,\dots,c$ at time $T$
\end{itemize}
\item $\hat{Y}(T)\in\mathbb{R}^{n\times c}$: the supervised information (again missing information can be padded by $0$) observed at $t=T$
\end{itemize}
\end{frame}

\begin{frame}{Model Instance (3)}\[
\begin{split}
\argmin_{W_e,b_e,W_d,b_d}\text{ }&\mathcal{L}=\int_0^T\mathcal{R}(t)dt-\sum_{i=1}^n\sum_{k=1}^c\hat{Y}_{i,k}(T)\log Y_{i,k}(T)\\
\text{subject to }&X_h(0)=\tanh(X(0)W_e+b_e)\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t))\\
&X(T)=\text{Softmax}(X_h(T)W_d+b_d)
\end{split}
\]
\begin{itemize}
\item We use differential equation system $\frac{dX(t)}{dt}=\text{ReLU}(\Phi X(t))$ to spread the graph signals over continuous time $[0,T]$, i.e.,\[
X_h(T)=X_h(0)+\int_0^T\text{ReLU}(\Phi X_h(t))
\]
\end{itemize}
\end{frame}

\begin{frame}{Model Instance (4)}\[
\begin{split}
\argmin_{W_e,b_e,W_d,b_d}\text{ }&\mathcal{L}=\int_0^T\mathcal{R}(t)dt-\sum_{i=1}^n\sum_{k=1}^c\hat{Y}_{i,k}(T)\log Y_{i,k}(T)\\
\text{subject to }&X_h(0)=\tanh(X(0)W_e+b_e)\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t))\\
&X(T)=\text{Softmax}(X_h(T)W_d+b_d)
\end{split}
\]
\begin{itemize}
\item Compared with the continuous-time model instance, we only have supervised information from one shapshot at time $t=T$
\item Thus we model the running loss as the $\ell_2$-norm regularizer of the learnable parameters to avoid overfitting: $\int_0^T\mathcal{R}(t)dt=\lambda(|W_e|_2^2+|b_e|_2^2+|W_d|_2^2+|b_d|_2^2)$
\end{itemize}
\end{frame}


\begin{frame}{Model Instance (5)}\[
\begin{split}
\argmin_{W_e,b_e,W_d,b_d}\text{ }&\mathcal{L}=\int_0^T\mathcal{R}(t)dt-\sum_{i=1}^n\sum_{k=1}^c\hat{Y}_{i,k}(T)\log Y_{i,k}(T)\\
\text{subject to }&X_h(0)=\tanh(X(0)W_e+b_e)\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t))\\
&X(T)=\text{Softmax}(X_h(T)W_d+b_d)
\end{split}
\]
\begin{itemize}
\item We adopt the diffusion operator $\Phi=\tilde{D}^{-\frac{1}{2}}(\alpha I+(1-\alpha)A)\tilde{D}^{-\frac{1}{2}}$ where $A$ is the adjacency matrix, $D$ is the degree matrix and $\tilde{D}=\alpha I+(1-\alpha)D$ keeps $\Phi$ normalized
\end{itemize}
\end{frame}


\begin{frame}{Model Instance (6)}\[
\begin{split}
\argmin_{W_e,b_e,W_d,b_d}\text{ }&\mathcal{L}=\int_0^T\mathcal{R}(t)dt-\sum_{i=1}^n\sum_{k=1}^c\hat{Y}_{i,k}(T)\log Y_{i,k}(T)\\
\text{subject to }&X_h(0)=\tanh(X(0)W_e+b_e)\\
&\frac{dX_h(t)}{dt}=\text{ReLU}(\Phi X_h(t))\\
&X(T)=\text{Softmax}(X_h(T)W_d+b_d)
\end{split}
\]
\begin{itemize}
\item The parameter $\alpha\in[0,1]$ tunes nodes' adherence to their previous information or their neighbors' collective opinion
\item We use $\alpha$ as a hyper-parameter here for simplicity and we can make it as a learnable parameter later
\end{itemize}
\end{frame}

\begin{frame}{Model Instance (7)}
\begin{itemize}
\item The differential equation system $\frac{dX}{dt}=\Phi X$ follows the dynamics of averaging the neighborhood opinion as\[
\begin{split}
\frac{d\overrightarrow{x_i(t)}}{dt}=&\frac{\alpha}{(1-\alpha)d_i+\alpha}\overrightarrow{x_i(t)}+\\
&\sum_j^n A_{i,j}\frac{1-\alpha}{\sqrt{(1-\alpha)d_i+\alpha}\sqrt{(1-\alpha)d_j+\alpha}}\overrightarrow{x_j(t)}
\end{split}
\]for node $i$
\item When $\alpha=0$, $\Phi$ averages the nieghbors as normalized random walk
\item When $\alpha=1$, $\Phi$ captures exponential dynamics without network effects
\item When $\alpha=0.5$, $\Phi$ averages both neighbors and itself
\end{itemize}
\end{frame}

\subsection{Experiments}
\begin{frame}{Results (1)}
\begin{itemize}
\item NDCN outperforms many s.o.t.a. GNN models
\item We report the mean and standard deviation of our results for $100$ runs
\item Cora dataset: terminal time $T=1.2,\alpha=0$
\item Citeseer dataset: $T=1.0,\alpha=0.8$
\item Pubmed dataset: $T=1.1,\alpha=0.4$
\end{itemize}
\end{frame}

\begin{frame}{Results (2)}
\begin{itemize}
\item NDCN gives better classification accuracy at terminal time $T\in\mathbb{R}^+$ by capturing the continous-time network dynamcis to diffuse network siignals
\item For all the three datasets their accuracy curves follow rise and fall patterns arounud the best terminal time
\item When the terminal time $T$ is too small or too large, the accuracy degenerates because the features of nodes are in under-diffusion or over-diffusion states, implying the necessity in capturing continuous-time dynamics
\item In contrast, previous GNNs can only have an discrete number of layers which cannot capture the continuous-time network dynamics accurately
\end{itemize}
\end{frame}

\end{document}
